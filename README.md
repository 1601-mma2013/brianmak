# Painting Musicallization: A Painting Based Algorithmic Composition
# I. Analysis
## 1. Research  
### a. Scope
Painting Musicallization is a prototype application artwork that composes and generates music based on a digitized painting. The application scans and analyzes the color and light intensity of the painting and synthesizes a reconstructed melody based on various musical theories. A custom computer aesthetic algorithm is deployed in music generation to simulate a human-composed melody. The approach mimics how a music composer arranges music notes in general. This prototype best benefits museums and art galleries to generate a unique music for each painting. The prototype provides a better experience option for the visitors when viewing the art works by allowing the visitors to “listen” to the painting while enjoying the painting visually as an added value to greater visiting experience. This also allows the visually impaired to appreciate visual art through the generated music. The prototype artwork is built on a generic algorithm that can recompose a melody for any paintings.

### b. Audit
Generative music and algorithmic composition have been around for more than half a century since Lejaren Hiller and Iannis Xenakis pioneered this technology. Illiac Suite, the first score to be composed by an electronic computer [2], is an exploration of four different music generating techniques including the generation of cantus firmi, generation of four-voice segments with various rules, dealing with rhythm, dynamics and playing instructions, and experiment with various models and probabilities for generative grammars or Markov chains [3].
Generative music and algorithmic composition are further developed and deployed by computer engineers atonal to tonal melody and from stochastic to structural coherent musical piece. These compositional processes are classified into four primary perspectives including linguistic/structural, interactive/behavioural, creative/procedural and biological/emergent. [4] Theories such as Generative Theory of Tonal Music formally described “the musical intuitions of a listener who is experienced in a musical idiom” to illuminate the unique human capacity for musical understanding. [5] Cognitive Constraints on Compositional System proposed the concept of musical grammar as “a limited set of rules that can generate indefinitely large sets of musical events and/or their structural descriptions,” to bridge the “huge gap between compositional system and cognized result.” [6]
Various approaches in automated compositions are used throughout the history from “early American efforts to impose stylistic controls through random sampling and testing” to “European statistical approaches used until 1970” to “the rise of ‘interactive’ compositional utilities during the 1970s” to “a period of eclectic interests: the resurgenće of statistical procedures, the introduction of ‘top-down’ recursive grammars, the adaptation of problem-solving techniques from Artificial Intelligence and the continuation of interactive efforts.” [7]
Several related algorithmic composition techniques were invented to synthesize musical pieces. Autonomous Evolutionary Music Composer [8] generates “interesting pieces of music that were both innovative and musically sound” using Genetic Algorithms. It combines and transposes musical motifs
generated by the system fit the phrases according to evaluations done by the Genetic Algorithm. Grammar- Based Automated Music Composition in Haskell [9] presents a new class of generative grammars called Probabilistic Temporal Graph Grammars to handle features like harmonic structure, metrical structure, musical phrase and temporal aspects, which are struggles to the preceding techniques. Cognitive Factors In Generative Music Systems [10] uses principles drawn from research into music perception and cognition to create music that meet the expectations of the human mind. This technique allows the system to create music that is “perceptually more meaningful for the listener.” Tambr [11] uses machine- learning methods like sentiment analysis to translate text into musical pieces that represents that sentiment in terms of chord quality.

### c. Stakeholder Interviews (internal / external)
1. Project Vision 

In this creative prototype, a new way of appreciating a visual art is introduced through the usage of different modality to enhance the viewing experience of audiences. Algorithm to compose and generate melody based on elements found in the digital painting successfully composes the generative melody and moderates the music composition. A new perspective is introduced to an overall curation of an art gallery.
The usage of melody and music composition based on musical theory sees as a good approach to let audiences listen to the painting and its other expressive values inside the picture. As compared to just only deduce the pixels features and match with melody and musical keys, the music is not composed and melody is not arranged in a best aesthetical sonic experience for audiences. Introducing a generative melody algorithm to compose music in an appropriate manner thus increase the experience in sonic art through the experiment with several types of paintings input to the installation.

2. Constraints 

Several images is tested on the creative prototype and the outcome varies. Some paintings with brighter complexion and complexities receive different interesting melody as a result of the music composition algorithm that matches the elements with normalization of the chords and music key. Other paintings with different complexities and complexion are tested and produce different kind of melody based on the strokes and painting styles too.

3. Opportunities 

This work has a great potential for future works. Besides engaging multimodal experience in an artwork, the creative prototype allows new perspective of utilizing a machine learning strategy adopt to visual and sonic art representation that brings a revolution to the whole new experience to audiences. Future works also includes the adaptation of the composition algorithm to produce various genre of music or melody based on the different genre of digital painting and print.

4. Users 

Computer technology is used to enhance the audience overall experience especially in a museum or gallery set up. In a setup of an art gallery, user experience is an important factor and it is usually depends on the
curation of the gallery with the artwork carefully arranged in a spacious exhibiting space. Generative melody using computer technology involves algorithm that forms the melody based on the digital copy of the existing painting and thus added a modality for a traditional painting to express as an new media art. Therefore, the curation of the art gallery is embedded with the generative melody and even the visually impaired audiences are able to appreciate the paintings.
This also allows the visually impaired to appreciate visual art through the generated music. The prototype artwork is built on a generic algorithm that can recompose a melody for any paintings.

### d. User observations
Understand user needs and behavior and describe it.
Find various aspect of audience/customer
 
1. Users

2. potential users

3. (user’s) behaviors

4. (user’s) attitudes

5. (user’s) aptitudes
	- users’s ability to learn something quickly and do it well

6. (user’s) motivations

7. (user’s) environments

8. (user’s) tools

9. (user’s) challenges

## 2. Modeling
### a. Personas
user and customer archetypes

1. **goals**

2. Patterns in user and customer behaviors

3. attitudes

4. aptitudes

5. environments

6. tools

7. challenges

### b. Other Models
Represent domain factors beyond individual users and customers
1. Workflows among multiple people

2. environments

3. artifacts

# II. Synthesis
## 1. Requirements Definition
### a. Context Scenarios
A sample context scenario

The following is the first iteration of a context scenario for a primary persona for a personal digital assistant (PDA) type phone, including both the device and its service. Our persona is Vivien Strong, a real-estate agent in Indianapolis, whose goals are to balance work and home life, close the deal, and make each client feel like he or she is her only client.

Here is Vivien’s context scenario:

1. While getting ready in the morning, Vivien uses her phone to check her e-mail. Because it has a relatively large screen and quick connection time, it’s more convenient than booting up a computer as she rushes to make her daughter, Alice, a sandwich for school.
2. Vivien sees an e-mail from her newest client, Frank, who wants to look at a house this afternoon. The device has his contact info, so she can call him with a simple action right from the e-mail.
3. While on the phone with Frank, Vivien switches to speakerphone so she can view the screen while talking. She looks at her appointments to see when she’s free. When she creates a new appointment, the phone automatically makes it an appointment with Frank, because it knows with whom she is talking. She quickly enters the address of the property into the appointment as she finishes her conversation.
4. After sending Alice to school, Vivien heads into the real-estate office to gather some papers for another appointment. Her phone has already updated her Outlook appointments, so the rest of the office knows where she’ll be in the afternoon.
5. The day goes by quickly, and eventually Vivien is running a bit late. As she heads toward the property she’ll be showing Frank, the phone alerts her that her appointment is in 15 minutes. When she flips open the phone, she sees not only the appointment, but also a list of all documents related to Frank, including e-mails, memos, phone messages, and call logs to Frank’s number. Vivien initiates a call, and the phone automatically connects to Frank because it knows her appointment with him is soon. She lets him know she’ll be there in 20 minutes.
6. Vivien knows the address of the property but is unsure exactly where it is. She pulls over and taps the address she put into the appointment. The phone downloads directions along with a thumbnail map showing her location relative to the destination.
7. Vivien gets to the property on time and starts showing it to Frank. She hears the phone ring from her purse. Normally while she is in an appointment, the phone automatically goes to voicemail, but Alice has a code she can press to get through. The phone knows it’s Alice calling, so it uses a distinctive ringtone.
8. Vivien takes the call. Alice missed the bus and needs to be picked up. Vivien calls her husband to see if he can do it. She gets his voicemail; he must be out of service range. She tells him she’s with a client and asks if he can get Alice. Five minutes later the phone sounds a brief tone. Vivien recognizes it as her husband’s; she sees he’s sent her an instant message: “I’ll get Alice; good luck on the deal!”

Notice how the scenario remains at a fairly high level, without getting too specific about interfaces or technologies. It’s important to create scenarios that are within the realm of technical possibility, but at this stage the details of reality are unimportant. We want to leave the door open for truly novel solutions, and it’s always possible to scale back; we are ultimately trying to describe an optimal, yet still feasible, experience. Also notice how the activities in the scenario tie back to Vivien’s goals and try to eliminate as many tasks as possible.
### b. Requirements
Describe necessary capabilities of the product
- Functional and data needs
- user mental models
- design imperatives
- product vision
- business requirements
- technology

## 2. Design Framework
### a. Elements
Deﬁne manifestations of information and functionality
1. Information
	2. form factor
	3. posture
	4. input method

2. functional and data elements
	- information
	- functions
	- mechanisms
	- actions
	- domain object models

### b. Framework
###System Design Overview
This algorithmic composition system synthesizes a melodic music in the Western music scale based on the composition of the painting. It is a translational model that produces musical piece by translating pixels information from digitized paintings. It cuts the digitized painting into multiple small quadrants to be analyzed and compared on colors and light intensity. Raster scan technique is used to scan through each quadrant while analysing the colors and light intensity of each group. The result of the color analysis is then used to determine the chord and scale of the following bar, major or minor. The chord is then played in the background as harmony. The system then maps the light intensities of the quadrants into a pentatonic scale of the determined chord creating a soothing melody.
####Cutting and grouping
Digital images usually populates nearby pixels with similar color and intensity. Thus making playing every pixel redundant. The strategy of grouping the pixels into small quadrants (Figure 2) and analyzing the pixels within the quadrants allows the system to play each quadrant as a note while avoiding redundancy. 
####Scanning of quadrants
Raster scanning technique (Figure 3) is applied on scanning each quadrant as it can efficiently converts the paintings into music without losing the intended composition made by the painter. Each horizontal scan line is translated into a passage of the music containing 4 or 8 bars while the whole painting is translated into a whole musical piece containing multiple passages depending on the height to width ratio of the painting. This approach allows the system to convert the horizontal visual composition of a painting into musical compositions of passages of the music while converting the vertical visual composition of the painting into the whole arrangement or composition of the entire pieces. 
####Chroma analysis and chord progression
The average color of the pixels in each quadrant is analyzed to determine if it is a warm or cool color based on general color theories (Figure 2). Warm colors is then mapped to a major musical scale while cool colors is mapped to a minor musical scale. The reason behind this is that warm colors give similar psychological and emotional effects as a major musical scale and vise versa. This helps the system to more accurately translate the composition of the paintings into music on an emotional level. A I, IV or V chord is selected for a warm quadrant while ii, iii or vi chord is selected for a cool quadrant based on the intensity of the quadrant.
####Color mapping
Intensity or value of the colors in each quadrant is mapped onto a scale of the chord determined from chroma analysis. A quadrant with high light intensity is mapped to a high pitch note while a quadrant with low light intensity is mapped to a low pitch value within the determined scale following a set of musical linguistic rules. This approach allows the generated music to maintain the range high and low notes similar to the range of bright and dark color used by the painter. 
####Post-processing
A few enhancements are applied to the generated raw music to mimic a human-composed melody. Multiple linguistic and structural rules are deployed to produce structural coherence in the musical pieces. All the downbeats (first beats of every bars) and the third beats are accented while the subdivisions (eighth and sixteenth notes) are softened. Notes that are not downbeats nor the third beats might be excluded or soften if the current note is same as the previous note or the current quadrant has a very low light intensity. Musical dynamics (loudness) and sustains (echo) is also introduced accordingly to produce a full sounding piece of music.
2. Key path Scenario



#References
1. Chong T. Wei, Gabriel Z. Chew, Wong J. Xen and Wong C. Onn. Listen To Your Eye- Turn the Visual into Sound. 2015. ACE ‘15. ACM 978-1-4503-3852- 3/15/11. http://dx.doi.org/10.1145/2832932.2832938
2. Andrew Stiller, Lejaren A. Hiller. 2001. Grove Music Online. (January 2001).
3. Lejaren A. Hiller, Leonard M. Isaacsn. 1959. Experimental Music: Composition With an Electronic Computer, second edition (New York: McGraw-Hill, 1959): 5–7.
4. Wooller, R., A. R. Brown, et al. 2005. A framework for comparison of processes in algorithmic music systems. Generative Arts Practice, Sydney, Creativity and Cognition Studios Press, pp. 109- 124.
5. Lerdahl, Fred and Ray Jackendoff. 1983. A generative theory of tonal music. Cambridge, MA: MIT Press.
6. Lerdahl, Fred. 1988. "Cognitive Constraints on Compositional Systems." In Generative Processes in Music: The Psychology of Performance, Improvisation, and Composition, ed. John Sloboda, 231-59. Oxford: Oxford University Press. Reprinted in Contemporary Music Review 6/2 (1992), pp. 97- 121
7. Charles Ames. 1987. Automated Composition in Retrospect: 1956-1986. LEONARDO, Vol. 20, No. 2, Special Issue: Visual Art, Sound, Music and Technology (1987) pp. 169-185.
8. Khalifa, M. Basel Al-Mourad. 2006. Autonomous Evolutionary Music Composer. GECCO’06, July 8– 12, 2006.. ACM 1-59593-186-4/06/0007.
9. Donya Quick, Paul Hudak. 2013. Grammar-Based Automated Music Composition in Haskell. FARM ‘13,ACM 978-1-4503-2386-4/13/09
10. Jim Bevington, Don Knox. 2014. Cognitive Factors In Generative Music Systems. AM ‘14, ACM 978-1- 4503-3032-9/14/10
11. Jessie Salas. 2016. Tambr. Retrieved June 10, 2016 from http://tambr.ml/
