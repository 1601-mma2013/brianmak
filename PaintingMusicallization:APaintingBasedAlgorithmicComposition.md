# Painting Musicallization: A Painting Based Algorithmic Composition
# I. Analysis
## 1. Research  
### a. Scope
Painting Musicallization is a prototype application artwork that composes and generates music based on a digitized painting. The application scans and analyzes the color and light intensity of the painting and synthesizes a reconstructed melody based on various musical theories. A custom computer aesthetic algorithm is deployed in music generation to simulate a human-composed melody. The approach mimics how a music composer arranges music notes in general. This prototype best benefits museums and art galleries to generate a unique music for each painting. The prototype provides a better experience option for the visitors when viewing the art works by allowing the visitors to “listen” to the painting while enjoying the painting visually as an added value to greater visiting experience. This also allows the visually impaired to appreciate visual art through the generated music. The prototype artwork is built on a generic algorithm that can recompose a melody for any paintings.

### b. Audit
Generative music and algorithmic composition have been around for more than half a century since Lejaren Hiller and Iannis Xenakis pioneered this technology. Illiac Suite, the first score to be composed by an electronic computer [2], is an exploration of four different music generating techniques including the generation of cantus firmi, generation of four-voice segments with various rules, dealing with rhythm, dynamics and playing instructions, and experiment with various models and probabilities for generative grammars or Markov chains [3].
Generative music and algorithmic composition are further developed and deployed by computer engineers atonal to tonal melody and from stochastic to structural coherent musical piece. These compositional processes are classified into four primary perspectives including linguistic/structural, interactive/behavioural, creative/procedural and biological/emergent. [4] Theories such as Generative Theory of Tonal Music formally described “the musical intuitions of a listener who is experienced in a musical idiom” to illuminate the unique human capacity for musical understanding. [5] Cognitive Constraints on Compositional System proposed the concept of musical grammar as “a limited set of rules that can generate indefinitely large sets of musical events and/or their structural descriptions,” to bridge the “huge gap between compositional system and cognized result.” [6]
Various approaches in automated compositions are used throughout the history from “early American efforts to impose stylistic controls through random sampling and testing” to “European statistical approaches used until 1970” to “the rise of ‘interactive’ compositional utilities during the 1970s” to “a period of eclectic interests: the resurgenće of statistical procedures, the introduction of ‘top-down’ recursive grammars, the adaptation of problem-solving techniques from Artificial Intelligence and the continuation of interactive efforts.” [7]
Several related algorithmic composition techniques were invented to synthesize musical pieces. Autonomous Evolutionary Music Composer [8] generates “interesting pieces of music that were both innovative and musically sound” using Genetic Algorithms. It combines and transposes musical motifs
generated by the system fit the phrases according to evaluations done by the Genetic Algorithm. Grammar- Based Automated Music Composition in Haskell [9] presents a new class of generative grammars called Probabilistic Temporal Graph Grammars to handle features like harmonic structure, metrical structure, musical phrase and temporal aspects, which are struggles to the preceding techniques. Cognitive Factors In Generative Music Systems [10] uses principles drawn from research into music perception and cognition to create music that meet the expectations of the human mind. This technique allows the system to create music that is “perceptually more meaningful for the listener.” Tambr [11] uses machine- learning methods like sentiment analysis to translate text into musical pieces that represents that sentiment in terms of chord quality.

### c. Stakeholder Interviews (internal / external)
#### Project Vision 
In this creative prototype, a new way of appreciating a visual art is introduced through the usage of different modality to enhance the viewing experience of audiences. Algorithm to compose and generate melody based on elements found in the digital painting successfully composes the generative melody and moderates the music composition. A new perspective is introduced to an overall curation of an art gallery.
The usage of melody and music composition based on musical theory sees as a good approach to let audiences listen to the painting and its other expressive values inside the picture. As compared to just only deduce the pixels features and match with melody and musical keys, the music is not composed and melody is not arranged in a best aesthetical sonic experience for audiences. Introducing a generative melody algorithm to compose music in an appropriate manner thus increase the experience in sonic art through the experiment with several types of paintings input to the installation.

#### Constraints 
Several images is tested on the creative prototype and the outcome varies. Some paintings with brighter complexion and complexities receive different interesting melody as a result of the music composition algorithm that matches the elements with normalization of the chords and music key. Other paintings with different complexities and complexion are tested and produce different kind of melody based on the strokes and painting styles too.

#### Opportunities 
This work has a great potential for future works. Besides engaging multimodal experience in an artwork, the creative prototype allows new perspective of utilizing a machine learning strategy adopt to visual and sonic art representation that brings a revolution to the whole new experience to audiences. Future works also includes the adaptation of the composition algorithm to produce various genre of music or melody based on the different genre of digital painting and print.

#### Users 
Computer technology is used to enhance the audience overall experience especially in a museum or gallery set up. In a setup of an art gallery, user experience is an important factor and it is usually depends on the
curation of the gallery with the artwork carefully arranged in a spacious exhibiting space. Generative melody using computer technology involves algorithm that forms the melody based on the digital copy of the existing painting and thus added a modality for a traditional painting to express as an new media art. Therefore, the curation of the art gallery is embedded with the generative melody and even the visually impaired audiences are able to appreciate the paintings.
This also allows the visually impaired to appreciate visual art through the generated music. The prototype artwork is built on a generic algorithm that can recompose a melody for any paintings.

## 2. Modeling
### a. Personas
Kimy G is a art currator for a visual art gallery. He awares that the audiences of the gallery find the musics playing at the background in the gallery do not suit the feeling of the visual art piece.

#### Goal
To play specific background music designed particularly for each visual art piece.

#### Patterns in user and customer behaviors
Mediums of exhibiting artworks:
Colored Photography
B&W Photography
Painting
Drawings
Others

#### Attitudes
He believes that background music strongly contributes to the enjoyment of visual art pieces.
He does not have the resources to have a human composer to compose music for each of the pieces.

#### Aptitudes
He can photograph a visual art piece and digitize it.
He can use a computer.
He can use simple computer programs.

#### Environments
He works in a visual art gallery. The gallery contains artwork of different genre of visual artwork from different era.

#### Tools
Computer, digital camera, speaker.

#### Challenges
Various image processing techniques including sectioning images into quadrants, image chroma analysis and image value analysis.
Multiple music composition theories, rules and techniques.

# II. Synthesis
## 1. Requirements Definition
### Context Scenarios
1. While getting ready for a new visual art exhibition, Vivien, a curator at a visual art gallery, needs background musics that suits each of the exhibiting artworks to be played across the gallery.
2. Vivien takes digital photographs of the exhibiting artworks and transfer them to a computer.
3. Vivien then opens Painting Musicallization Program and feeds the images she has taken into the program.
4. The program then automatically "converts" the images into sooting musical pieces suited to each and everyone of the artworks.
5. She then plays each of the musical pieces on each of the exhibiting visual artworks using regular speakers.
6. As the exhibition starts, the audiences come into the gallery and love the experience of watching the visual artworks with the music generated by Painting Musicallization Program.
7. Visually impaired audiences come to the gallery as well to experience the composition of the artworks through the music generated by Painting Musicallization Program

## 2. Design Framework
###System Design Overview
This algorithmic composition system synthesizes a melodic music in the Western music scale based on the composition of the painting. It is a translational model that produces musical piece by translating pixels information from digitized paintings. It cuts the digitized painting into multiple small quadrants to be analyzed and compared on colors and light intensity. Raster scan technique is used to scan through each quadrant while analysing the colors and light intensity of each group. The result of the color analysis is then used to determine the chord and scale of the following bar, major or minor. The chord is then played in the background as harmony. The system then maps the light intensities of the quadrants into a pentatonic scale of the determined chord creating a soothing melody.
####Cutting and grouping
Digital images usually populates nearby pixels with similar color and intensity. Thus making playing every pixel redundant. The strategy of grouping the pixels into small quadrants (Figure 2) and analyzing the pixels within the quadrants allows the system to play each quadrant as a note while avoiding redundancy. 
####Scanning of quadrants
Raster scanning technique (Figure 3) is applied on scanning each quadrant as it can efficiently converts the paintings into music without losing the intended composition made by the painter. Each horizontal scan line is translated into a passage of the music containing 4 or 8 bars while the whole painting is translated into a whole musical piece containing multiple passages depending on the height to width ratio of the painting. This approach allows the system to convert the horizontal visual composition of a painting into musical compositions of passages of the music while converting the vertical visual composition of the painting into the whole arrangement or composition of the entire pieces. 
####Chroma analysis and chord progression
The average color of the pixels in each quadrant is analyzed to determine if it is a warm or cool color based on general color theories (Figure 2). Warm colors is then mapped to a major musical scale while cool colors is mapped to a minor musical scale. The reason behind this is that warm colors give similar psychological and emotional effects as a major musical scale and vise versa. This helps the system to more accurately translate the composition of the paintings into music on an emotional level. A I, IV or V chord is selected for a warm quadrant while ii, iii or vi chord is selected for a cool quadrant based on the intensity of the quadrant.
####Color mapping
Intensity or value of the colors in each quadrant is mapped onto a scale of the chord determined from chroma analysis. A quadrant with high light intensity is mapped to a high pitch note while a quadrant with low light intensity is mapped to a low pitch value within the determined scale following a set of musical linguistic rules. This approach allows the generated music to maintain the range high and low notes similar to the range of bright and dark color used by the painter. 
####Post-processing
A few enhancements are applied to the generated raw music to mimic a human-composed melody. Multiple linguistic and structural rules are deployed to produce structural coherence in the musical pieces. All the downbeats (first beats of every bars) and the third beats are accented while the subdivisions (eighth and sixteenth notes) are softened. Notes that are not downbeats nor the third beats might be excluded or soften if the current note is same as the previous note or the current quadrant has a very low light intensity. Musical dynamics (loudness) and sustains (echo) is also introduced accordingly to produce a full sounding piece of music.
2. Key path Scenario



#References
1. Chong T. Wei, Gabriel Z. Chew, Wong J. Xen and Wong C. Onn. Listen To Your Eye- Turn the Visual into Sound. 2015. ACE ‘15. ACM 978-1-4503-3852- 3/15/11. http://dx.doi.org/10.1145/2832932.2832938
2. Andrew Stiller, Lejaren A. Hiller. 2001. Grove Music Online. (January 2001).
3. Lejaren A. Hiller, Leonard M. Isaacsn. 1959. Experimental Music: Composition With an Electronic Computer, second edition (New York: McGraw-Hill, 1959): 5–7.
4. Wooller, R., A. R. Brown, et al. 2005. A framework for comparison of processes in algorithmic music systems. Generative Arts Practice, Sydney, Creativity and Cognition Studios Press, pp. 109- 124.
5. Lerdahl, Fred and Ray Jackendoff. 1983. A generative theory of tonal music. Cambridge, MA: MIT Press.
6. Lerdahl, Fred. 1988. "Cognitive Constraints on Compositional Systems." In Generative Processes in Music: The Psychology of Performance, Improvisation, and Composition, ed. John Sloboda, 231-59. Oxford: Oxford University Press. Reprinted in Contemporary Music Review 6/2 (1992), pp. 97- 121
7. Charles Ames. 1987. Automated Composition in Retrospect: 1956-1986. LEONARDO, Vol. 20, No. 2, Special Issue: Visual Art, Sound, Music and Technology (1987) pp. 169-185.
8. Khalifa, M. Basel Al-Mourad. 2006. Autonomous Evolutionary Music Composer. GECCO’06, July 8– 12, 2006.. ACM 1-59593-186-4/06/0007.
9. Donya Quick, Paul Hudak. 2013. Grammar-Based Automated Music Composition in Haskell. FARM ‘13,ACM 978-1-4503-2386-4/13/09
10. Jim Bevington, Don Knox. 2014. Cognitive Factors In Generative Music Systems. AM ‘14, ACM 978-1- 4503-3032-9/14/10
11. Jessie Salas. 2016. Tambr. Retrieved June 10, 2016 from http://tambr.ml/
