# Painting Musicallization: A Painting Based Algorithmic Composition
# I. Analysis
## 1. Research  
### a. Scope
Music and sound plays an important role in creative imagination. Audio visualization enhances the visual experience and sometimes can extract information that an artist express in a painting as an extra modality to experience the artwork. Creative installation of listening to what the eye sees [1] added value to the visually impaired individuals to also hear the sound of colors in a controlled environment.
Painting Musicallization is a creative prototype that uses the music composition approach to normalize a music generated by elements in a digital painting. The analogy is using an imagination to listen to a painting with a soothing melody decomposed with strategies to uncover a better appreciation of a painting.
Listening to a painting can also provide an opportunity for the visually impaired audience to appreciate a painting especially in a gallery or museum. This creative prototype lets the audience listen to a composed melody that adds value to the painting and brings the painting alive.
In this creative prototype, images of different types of paintings are fed into the prototype and musical interpretation is deduced as a representation of the visually displayed painting. The melody is produced based on the algorithm composing music with compositional rules to provide a real generative melody based on detected components in a painting. The generative melody brings out the intrinsic representation of an interpretation of the painter’s motivation in the painting thus enriching the audience viewing experience.
Computer technology is used to enhance the audience overall experience especially in a museum or gallery set up. In a setup of an art gallery, user experience is an important factor and it is usually depends on the
curation of the gallery with the artwork carefully arranged in a spacious exhibiting space. Generative melody using computer technology involves algorithm that forms the melody based on the digital copy of the existing painting and thus added a modality for a traditional painting to express as an new media art. Therefore, the curation of the art gallery is embedded with the generative melody and even the visually impaired audiences are able to appreciate the paintings.
People have no experience on listening what they are seeing. Therefore, this is a creative way of bringing the message that is especially useful for visually impaired personnel as well as creating a relation between aesthetic of sight with aesthetic of sound. [1]
The contribution of this artwork brings a significant value to translate a digital painting into a generative melody that adds value to the experience of the audience in an art gallery. Besides, this multimodal approach also brings visually impaired audience close to visual art appreciation and its aesthetic representation in a different form.

### b. Audit
#### Related Works
Generative music and algorithmic composition have been around for more than half a century since Lejaren Hiller and Iannis Xenakis pioneered this technology. Illiac Suite, the first score to be composed by an electronic computer [2], is an exploration of four different music generating techniques including the generation of cantus firmi, generation of four-voice segments with various rules, dealing with rhythm, dynamics and playing instructions, and experiment with various models and probabilities for generative grammars or Markov chains [3].
Generative music and algorithmic composition are further developed and deployed by computer engineers atonal to tonal melody and from stochastic to structural coherent musical piece. These compositional processes are classified into four primary perspectives including linguistic/structural, interactive/behavioural, creative/procedural and biological/emergent. [4] Theories such as Generative Theory of Tonal Music formally described “the musical intuitions of a listener who is experienced in a musical idiom” to illuminate the unique human capacity for musical understanding. [5] Cognitive Constraints on Compositional System proposed the concept of musical grammar as “a limited set of rules that can generate indefinitely large sets of musical events and/or their structural descriptions,” to bridge the “huge gap between compositional system and cognized result.” [6]
Various approaches in automated compositions are used throughout the history from “early American efforts to impose stylistic controls through random sampling and testing” to “European statistical approaches used until 1970” to “the rise of ‘interactive’ compositional utilities during the 1970s” to “a period of eclectic interests: the resurgenće of statistical procedures, the introduction of ‘top-down’ recursive grammars, the adaptation of problem-solving techniques from Artificial Intelligence and the continuation of interactive efforts.” [7]
Several related algorithmic composition techniques were invented to synthesize musical pieces. Autonomous Evolutionary Music Composer [8] generates “interesting pieces of music that were both innovative and musically sound” using Genetic Algorithms. It combines and transposes musical motifs
generated by the system fit the phrases according to evaluations done by the Genetic Algorithm. Grammar- Based Automated Music Composition in Haskell [9] presents a new class of generative grammars called Probabilistic Temporal Graph Grammars to handle features like harmonic structure, metrical structure, musical phrase and temporal aspects, which are struggles to the preceding techniques. Cognitive Factors In Generative Music Systems [10] uses principles drawn from research into music perception and cognition to create music that meet the expectations of the human mind. This technique allows the system to create music that is “perceptually more meaningful for the listener.” Tambr [11] uses machine- learning methods like sentiment analysis to translate text into musical pieces that represents that sentiment in terms of chord quality.

### c. Stakeholder Interviews (internal / external)
#### Project Vision 
In this creative prototype, a new way of appreciating a visual art is introduced through the usage of different modality to enhance the viewing experience of audiences. Algorithm to compose and generate melody based on elements found in the digital painting successfully composes the generative melody and moderates the music composition. A new perspective is introduced to an overall curation of an art gallery.
The usage of melody and music composition based on musical theory sees as a good approach to let audiences listen to the painting and its other expressive values inside the picture. As compared to just only deduce the pixels features and match with melody and musical keys, the music is not composed and melody is not arranged in a best aesthetical sonic experience for audiences. Introducing a generative melody algorithm to compose music in an appropriate manner thus increase the experience in sonic art through the experiment with several types of paintings input to the installation.

#### Constraints 
Several images is tested on the creative prototype and the outcome varies. Some paintings with brighter complexion and complexities receive different interesting melody as a result of the music composition algorithm that matches the elements with normalization of the chords and music key. Other paintings with different complexities and complexion are tested and produce different kind of melody based on the strokes and painting styles too.

#### Opportunities 
This work has a great potential for future works. Besides engaging multimodal experience in an artwork, the creative prototype allows new perspective of utilizing a machine learning strategy adopt to visual and sonic art representation that brings a revolution to the whole new experience to audiences. Future works also includes the adaptation of the composition algorithm to produce various genre of music or melody based on the different genre of digital painting and print.

#### Users 
Computer technology is used to enhance the audience overall experience especially in a museum or gallery set up. In a setup of an art gallery, user experience is an important factor and it is usually depends on the
curation of the gallery with the artwork carefully arranged in a spacious exhibiting space. Generative melody using computer technology involves algorithm that forms the melody based on the digital copy of the existing painting and thus added a modality for a traditional painting to express as an new media art. Therefore, the curation of the art gallery is embedded with the generative melody and even the visually impaired audiences are able to appreciate the paintings.
This also allows the visually impaired to appreciate visual art through the generated music. The prototype artwork is built on a generic algorithm that can recompose a melody for any paintings.

## 2. Modeling
### a. Personas
Kimy G is a visual art collector who also loves visiting visual art galeries.

#### Goal
To purchase a visual art piece that Kimmy emotionally attach to

#### Patterns in user and customer behaviors
Kimy G make art acquisition base on his emotional attachment towards the art work.
Sound affects the mood and emotion of Kimy G.
Kimy G finds enjoying an artwork with a correct music playing at the background strongly increase the experience of looking at the visual art piece.

#### Attitudes
He believes that background music firmly contributes to the enjoyment of visual art pieces.

#### Aptitudes
He apprecietes a good music played when he is enjoying a piece of visual art.

#### Environments
Galleries containing artworks of different genres of visual artwork from different era.

#### Tools
Computer, digital camera, speaker.

#### Challenges
Various image processing techniques including sectioning images into quadrants, image chroma analysis and image value analysis.
Multiple music composition theories, rules and techniques.

# II. Synthesis
## 1. Requirements Definition
### Context Scenarios
1. Kimmy does not enjoy going to a visual art gallery as most of the visual art galleries are either unduly quiet or play unrelated musics that distrub/ruin the experience of the visit.
2. Kimmy finds out that Visual Art Gallery A has implemented Painting Musicallization Program in all of the exhibiting visual art.
3. Kimmy goes to the gallery and finds that the background music for each of the visual artworks are paired with background music that not only reflects the mood of the artworks but the visual compositions as well.
4. Kimmy enjoy his experience at the gallery and decided to purchase few of the pieces due to the enhanced emotional experience provided by the background music generated by Painting Musicallization

## 2. Design Framework
### System Design Overview
This algorithmic composition system synthesizes a melodic music in the Western music scale based on the composition of the painting. It is a translational model that produces musical piece by translating pixels information from digitized paintings. It cuts the digitized painting into multiple small quadrants to be analyzed and compared on colors and light intensity. Raster scan technique is used to scan through each quadrant while analysing the colors and light intensity of each group. The result of the color analysis is then used to determine the chord and scale of the following bar, major or minor. The chord is then played in the background as harmony. The system then maps the light intensities of the quadrants into a pentatonic scale of the determined chord creating a soothing melody. (Figure 1)

[![Screen_Shot_2016_09_26_at_11_53_23_PM.png](http://s18.postimg.org/llfefq6s5/Screen_Shot_2016_09_26_at_11_53_23_PM.png)](http://postimg.org/image/llfefq6s5/)

#### Cutting and grouping
Digital images usually populates nearby pixels with similar color and intensity. Thus making playing every pixel redundant. The strategy of grouping the pixels into small quadrants (Figure 2) and analyzing the pixels within the quadrants allows the system to play each quadrant as a note while avoiding redundancy. 

[![Screen_Shot_2016_09_26_at_11_53_31_PM.png](http://s18.postimg.org/t2t78olp1/Screen_Shot_2016_09_26_at_11_53_31_PM.png)](http://postimg.org/image/t2t78olp1/)

#### Scanning of quadrants
Raster scanning technique (Figure 2) is applied on scanning each quadrant as it can efficiently converts the paintings into music without losing the intended composition made by the painter. Each horizontal scan line is translated into a passage of the music containing 4 or 8 bars while the whole painting is translated into a whole musical piece containing multiple passages depending on the height to width ratio of the painting. This approach allows the system to convert the horizontal visual composition of a painting into musical compositions of passages of the music while converting the vertical visual composition of the painting into the whole arrangement or composition of the entire pieces. 

#### Chroma analysis and chord progression
The average color of the pixels in each quadrant is analyzed to determine if it is a warm or cool color based on general color theories (Figure 3). Warm colors is then mapped to a major musical scale while cool colors is mapped to a minor musical scale. The reason behind this is that warm colors give similar psychological and emotional effects as a major musical scale and vise versa. This helps the system to more accurately translate the composition of the paintings into music on an emotional level. A I, IV or V chord is selected for a warm quadrant while ii, iii or vi chord is selected for a cool quadrant based on the intensity of the quadrant.

[![Screen_Shot_2016_09_26_at_11_53_35_PM.png](http://s18.postimg.org/3y26v9m8l/Screen_Shot_2016_09_26_at_11_53_35_PM.png)](http://postimg.org/image/3y26v9m8l/)

#### Color mapping
Intensity or value of the colors in each quadrant is mapped onto a scale of the chord determined from chroma analysis. A quadrant with high light intensity is mapped to a high pitch note while a quadrant with low light intensity is mapped to a low pitch value within the determined scale following a set of musical linguistic rules. This approach allows the generated music to maintain the range high and low notes similar to the range of bright and dark color used by the painter. 

####Post-processing
A few enhancements are applied to the generated raw music to mimic a human-composed melody. Multiple linguistic and structural rules are deployed to produce structural coherence in the musical pieces. All the downbeats (first beats of every bars) and the third beats are accented while the subdivisions (eighth and sixteenth notes) are softened. Notes that are not downbeats nor the third beats might be excluded or soften if the current note is same as the previous note or the current quadrant has a very low light intensity. Musical dynamics (loudness) and sustains (echo) is also introduced accordingly to produce a full sounding piece of music.


#References
1. Chong T. Wei, Gabriel Z. Chew, Wong J. Xen and Wong C. Onn. Listen To Your Eye- Turn the Visual into Sound. 2015. ACE ‘15. ACM 978-1-4503-3852- 3/15/11. http://dx.doi.org/10.1145/2832932.2832938
2. Andrew Stiller, Lejaren A. Hiller. 2001. Grove Music Online. (January 2001).
3. Lejaren A. Hiller, Leonard M. Isaacsn. 1959. Experimental Music: Composition With an Electronic Computer, second edition (New York: McGraw-Hill, 1959): 5–7.
4. Wooller, R., A. R. Brown, et al. 2005. A framework for comparison of processes in algorithmic music systems. Generative Arts Practice, Sydney, Creativity and Cognition Studios Press, pp. 109- 124.
5. Lerdahl, Fred and Ray Jackendoff. 1983. A generative theory of tonal music. Cambridge, MA: MIT Press.
6. Lerdahl, Fred. 1988. "Cognitive Constraints on Compositional Systems." In Generative Processes in Music: The Psychology of Performance, Improvisation, and Composition, ed. John Sloboda, 231-59. Oxford: Oxford University Press. Reprinted in Contemporary Music Review 6/2 (1992), pp. 97- 121
7. Charles Ames. 1987. Automated Composition in Retrospect: 1956-1986. LEONARDO, Vol. 20, No. 2, Special Issue: Visual Art, Sound, Music and Technology (1987) pp. 169-185.
8. Khalifa, M. Basel Al-Mourad. 2006. Autonomous Evolutionary Music Composer. GECCO’06, July 8– 12, 2006.. ACM 1-59593-186-4/06/0007.
9. Donya Quick, Paul Hudak. 2013. Grammar-Based Automated Music Composition in Haskell. FARM ‘13,ACM 978-1-4503-2386-4/13/09
10. Jim Bevington, Don Knox. 2014. Cognitive Factors In Generative Music Systems. AM ‘14, ACM 978-1- 4503-3032-9/14/10
11. Jessie Salas. 2016. Tambr. Retrieved June 10, 2016 from http://tambr.ml/
